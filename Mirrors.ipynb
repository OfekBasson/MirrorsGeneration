{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":17944,"status":"ok","timestamp":1728994891805,"user":{"displayName":"Ofek Basson","userId":"13968683082406466135"},"user_tz":-180},"id":"poxs681YSfQW","outputId":"0a82be27-83d7-494e-ea25-ff17a3d0e379","vscode":{"languageId":"shellscript"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: diffusers in /opt/conda/lib/python3.11/site-packages (0.30.3)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.11/site-packages (from diffusers) (8.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from diffusers) (3.13.1)\n","Requirement already satisfied: huggingface-hub>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from diffusers) (0.25.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from diffusers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from diffusers) (2024.9.11)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from diffusers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from diffusers) (0.4.5)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from diffusers) (10.4.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.11.0)\n","Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.20.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers) (2024.7.4)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: invisible_watermark in /opt/conda/lib/python3.11/site-packages (0.2.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.45.2)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.0.1)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (0.4.5)\n","Requirement already satisfied: Pillow>=6.0.0 in /opt/conda/lib/python3.11/site-packages (from invisible_watermark) (10.4.0)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from invisible_watermark) (1.7.0)\n","Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from invisible_watermark) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /opt/conda/lib/python3.11/site-packages (from invisible_watermark) (4.10.0.84)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from invisible_watermark) (2.4.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->invisible_watermark) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->invisible_watermark) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->invisible_watermark) (3.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->invisible_watermark) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->invisible_watermark) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install diffusers --upgrade\n","!pip install invisible_watermark transformers accelerate safetensors\n","!apt-get install -y libgl1-mesa-glx\n","!pip install matplotlib"]},{"cell_type":"code","execution_count":2,"metadata":{"vscode":{"languageId":"shellscript"}},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","\n","login(token=\"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\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24307,"status":"ok","timestamp":1728996134365,"user":{"displayName":"Ofek Basson","userId":"13968683082406466135"},"user_tz":-180},"id":"lBdYvnZooxfD","outputId":"fedc5124-0da6-4bc9-e52f-f98e7477c3c9","vscode":{"languageId":"shellscript"}},"outputs":[],"source":["# TODO: Reorder imports\n","import sys\n","import torch\n","from diffusers import DiffusionPipeline, StableDiffusionXLPipeline\n","from diffusers.models.attention import Attention\n","from diffusers.models import Transformer2DModel\n","import matplotlib.pyplot as plt\n","from new_functions.attention_new_forward import new_attention_module_forward\n","from new_functions.pipe_new_call import pipe_new_call"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"cl8TCvDvnS4G","vscode":{"languageId":"shellscript"}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94fcf47c971449e288f5addc5bea8a35","version_major":2,"version_minor":0},"text/plain":["Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Inside '_batch_encode_plus' (tokenizer function), tokens are: ['a</w>', 'man</w>', 'in</w>', 'front</w>', 'of</w>', 'a</w>', 'ply', 'wood</w>']\n"]},{"ename":"UnboundLocalError","evalue":"cannot access local variable 'tokens' where it is not associated with a value","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Define the prompt and generate an image\u001b[39;00m\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA man in front of a plywood\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpipe_new_call(prompt\u001b[38;5;241m=\u001b[39mprompt)\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Visualize the generated image\u001b[39;00m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/MirrorsGeneration-1/new_functions/pipe_new_call.py:295\u001b[0m, in \u001b[0;36mpipe_new_call\u001b[0;34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m lora_scale \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_prompt \u001b[38;5;241m=\u001b[39m new_encode_prompt\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, StableDiffusionXLPipeline)\n\u001b[1;32m    287\u001b[0m (\n\u001b[1;32m    288\u001b[0m     prompt_embeds,\n\u001b[1;32m    289\u001b[0m     negative_prompt_embeds,\n\u001b[1;32m    290\u001b[0m     pooled_prompt_embeds,\n\u001b[1;32m    291\u001b[0m     negative_pooled_prompt_embeds,\n\u001b[1;32m    292\u001b[0m     tokenized_prompt, \n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# TODO: Understand if the tokenized_negative_prompt is necessary\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     tokenized_negative_prompt\n\u001b[0;32m--> 295\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_prompt(\n\u001b[1;32m    296\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    297\u001b[0m     prompt_2\u001b[38;5;241m=\u001b[39mprompt_2,\n\u001b[1;32m    298\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    299\u001b[0m     num_images_per_prompt\u001b[38;5;241m=\u001b[39mnum_images_per_prompt,\n\u001b[1;32m    300\u001b[0m     do_classifier_free_guidance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_classifier_free_guidance,\n\u001b[1;32m    301\u001b[0m     negative_prompt\u001b[38;5;241m=\u001b[39mnegative_prompt,\n\u001b[1;32m    302\u001b[0m     negative_prompt_2\u001b[38;5;241m=\u001b[39mnegative_prompt_2,\n\u001b[1;32m    303\u001b[0m     prompt_embeds\u001b[38;5;241m=\u001b[39mprompt_embeds,\n\u001b[1;32m    304\u001b[0m     negative_prompt_embeds\u001b[38;5;241m=\u001b[39mnegative_prompt_embeds,\n\u001b[1;32m    305\u001b[0m     pooled_prompt_embeds\u001b[38;5;241m=\u001b[39mpooled_prompt_embeds,\n\u001b[1;32m    306\u001b[0m     negative_pooled_prompt_embeds\u001b[38;5;241m=\u001b[39mnegative_pooled_prompt_embeds,\n\u001b[1;32m    307\u001b[0m     lora_scale\u001b[38;5;241m=\u001b[39mlora_scale,\n\u001b[1;32m    308\u001b[0m     clip_skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_skip,\n\u001b[1;32m    309\u001b[0m )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# 4. Prepare timesteps\u001b[39;00m\n\u001b[1;32m    312\u001b[0m timesteps, num_inference_steps \u001b[38;5;241m=\u001b[39m retrieve_timesteps(\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler, num_inference_steps, device, timesteps, sigmas\n\u001b[1;32m    314\u001b[0m )\n","File \u001b[0;32m~/MirrorsGeneration-1/new_functions/pipe_new_encode_prompt.py:117\u001b[0m, in \u001b[0;36mnew_encode_prompt\u001b[0;34m(self, prompt, prompt_2, device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt, negative_prompt_2, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, lora_scale, clip_skip)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, TextualInversionLoaderMixin):\n\u001b[1;32m    115\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_convert_prompt(prompt, tokenizer)\n\u001b[0;32m--> 117\u001b[0m text_inputs, tokenized_prompt \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m    118\u001b[0m     prompt,\n\u001b[1;32m    119\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    120\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_max_length,\n\u001b[1;32m    121\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m text_input_ids \u001b[38;5;241m=\u001b[39m text_inputs\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m    125\u001b[0m untruncated_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongest\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_ids\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3016\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3015\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3016\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3104\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3100\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3101\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3102\u001b[0m         )\n\u001b[1;32m   3103\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   3105\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3106\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   3107\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3108\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   3109\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m   3110\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[1;32m   3111\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[1;32m   3112\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m   3113\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[1;32m   3114\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m   3115\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m   3116\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m   3117\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m   3118\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m   3119\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m   3120\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m   3121\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   3122\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[1;32m   3123\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3124\u001b[0m     )\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3127\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3128\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3147\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3306\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3297\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3298\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3299\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3304\u001b[0m )\n\u001b[0;32m-> 3306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m   3307\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3308\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   3309\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m   3310\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   3311\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m   3312\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[1;32m   3313\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[1;32m   3314\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m   3315\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[1;32m   3316\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m   3317\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m   3318\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m   3319\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m   3320\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m   3321\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m   3322\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m   3323\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   3324\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3326\u001b[0m )\n","File \u001b[0;32m~/MirrorsGeneration-1/new_functions/tokenizer_new_functions.py:184\u001b[0m, in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n\u001b[1;32m    166\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_prepare_for_model(\n\u001b[1;32m    167\u001b[0m     input_ids,\n\u001b[1;32m    168\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[1;32m    183\u001b[0m )\n\u001b[0;32m--> 184\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens \u001b[38;5;28;01mif\u001b[39;00m tokens \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs), tokens\n","\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'tokens' where it is not associated with a value"]}],"source":["# TODO: Use the refiner from here: https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0\n","\n","# Load the pipeline\n","pipe = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n","pipe.pipe_new_call = pipe_new_call.__get__(pipe, StableDiffusionXLPipeline)\n","pipe.to(\"cuda\")\n","\n","# # Attach the hook to all cross-attention layers\n","for name, module in pipe.unet.named_modules():\n","    if name.endswith(\"attn2\") and isinstance(module, Attention):\n","      module.forward = new_attention_module_forward.__get__(module, Transformer2DModel)\n","      module.processor.concatenated_attention_maps = None\n","\n","# Define the prompt and generate an image\n","prompt = \"A man in front of a plywood\"\n","image = pipe.pipe_new_call(prompt=prompt).images[0]\n","\n","# Visualize the generated image\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOdRPosc+w3RUdS95Mp1aoi","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1e463f6f32d24d4e90c71c2d95124920":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c457ba4d5a849ba8f8366e50271b68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1590f7ddc47458ca8f90faa2fb7e921","placeholder":"​","style":"IPY_MODEL_699253e4c1b34c87805337b6e20cff08","value":"  0%"}},"43b6be3c2f8343c4bc62d7e8b0272816":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45f53a03a38f4c3bac0e83aec8654624":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92190736bd9b44109c7deb4aba7a1ba5","placeholder":"​","style":"IPY_MODEL_b030fd6d5b1a4b40b239663df9570aaa","value":"Loading pipeline components...: 100%"}},"61d1e980a70a425a8235adac935ab3cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c457ba4d5a849ba8f8366e50271b68a","IPY_MODEL_c7313e28ac524115bf7683c47724b3d5","IPY_MODEL_a88d6e6045944f97bc526dd220ab6965"],"layout":"IPY_MODEL_b350137e7aa84ac08e238dd08e8c7c62"}},"61eac66148664ae79ae97f73c0e4d1ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6895fbb236d64f4ebaee93714ab0bfc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"699253e4c1b34c87805337b6e20cff08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"787360ba16584583bb558cece7212a5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8eb123380dd6476a83edf89bf099dd1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912902ba1ac643909bc7ce82f5b5a99b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e463f6f32d24d4e90c71c2d95124920","placeholder":"​","style":"IPY_MODEL_61eac66148664ae79ae97f73c0e4d1ce","value":" 7/7 [00:04&lt;00:00,  1.62it/s]"}},"92190736bd9b44109c7deb4aba7a1ba5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a88d6e6045944f97bc526dd220ab6965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec29c1d8773341a09cc6a504d01dff91","placeholder":"​","style":"IPY_MODEL_6895fbb236d64f4ebaee93714ab0bfc1","value":" 0/50 [00:00&lt;?, ?it/s]"}},"b030fd6d5b1a4b40b239663df9570aaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b083b98fab1746b1a56c64be971eb62b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d385e003ad15436cb4f436f2025d1655","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edfd6a925e0d46b1bfe5c68d4d2f5900","value":7}},"b350137e7aa84ac08e238dd08e8c7c62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf7d802dbcbc4866ab0afb1e3393b271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45f53a03a38f4c3bac0e83aec8654624","IPY_MODEL_b083b98fab1746b1a56c64be971eb62b","IPY_MODEL_912902ba1ac643909bc7ce82f5b5a99b"],"layout":"IPY_MODEL_8eb123380dd6476a83edf89bf099dd1e"}},"c7313e28ac524115bf7683c47724b3d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b6be3c2f8343c4bc62d7e8b0272816","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_787360ba16584583bb558cece7212a5f","value":0}},"d1590f7ddc47458ca8f90faa2fb7e921":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d385e003ad15436cb4f436f2025d1655":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec29c1d8773341a09cc6a504d01dff91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfd6a925e0d46b1bfe5c68d4d2f5900":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
